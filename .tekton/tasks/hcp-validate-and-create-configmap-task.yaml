# SPDX-FileCopyrightText: 2025 SAP edge team
# SPDX-FileContributor: Manjun Jiao (@mjiao)
#
# SPDX-License-Identifier: Apache-2.0

---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: hcp-validate-and-create-configmap
spec:
  description: >-
    Validates hosted cluster deployment and creates a ConfigMap with cluster
    info for endpoint tests (host, ingressIP).
  params:
    - name: hostedClusterName
      type: string
      description: "Name of the hosted cluster"
    - name: hostedClusterNamespace
      type: string
      description: "Namespace for HostedCluster resources"
      default: "clusters"
    - name: hubKubeconfigSecretName
      type: string
      description: "Name of the Secret containing kubeconfig for hub cluster (optional)"
      default: ""
  workspaces:
    - name: source
  results:
    - name: cluster-summary
      description: "Brief cluster and services validation summary"
  steps:
    - name: validate-and-create-configmap
      image: registry.access.redhat.com/ubi9/ubi
      workingDir: $(workspaces.source.path)
      timeout: "336h"
      env:
        - name: HOSTED_CLUSTER_NAME
          value: "$(params.hostedClusterName)"
        - name: HOSTED_CLUSTER_NAMESPACE
          value: "$(params.hostedClusterNamespace)"
        - name: HUB_KUBECONFIG_SECRET
          value: "$(params.hubKubeconfigSecretName)"
      script: |
        #!/usr/bin/env bash
        set -euo pipefail

        echo "âœ… Validating HCP hosted cluster and creating endpoint test ConfigMap..."
        echo "=============================================="

        # Install required packages
        echo "ðŸ“¦ Installing required packages..."
        dnf install -y jq > /dev/null 2>&1

        # Install OpenShift CLI
        echo "ðŸ“¦ Installing OpenShift CLI..."
        curl -sL https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/openshift-client-linux.tar.gz -o /tmp/oc.tar.gz
        tar xzf /tmp/oc.tar.gz -C /tmp
        mv /tmp/oc /usr/local/bin/
        cp /usr/local/bin/oc /usr/local/bin/kubectl
        rm -f /tmp/oc.tar.gz
        oc version --client

        # Configure hub cluster kubeconfig if provided
        if [[ -n "${HUB_KUBECONFIG_SECRET}" ]]; then
          echo "ðŸ” Extracting hub cluster kubeconfig from secret: ${HUB_KUBECONFIG_SECRET}..."
          HUB_KUBECONFIG="/tmp/hub-kubeconfig"
          # Try different common key names for kubeconfig in secrets
          if kubectl get secret "${HUB_KUBECONFIG_SECRET}" -o jsonpath='{.data.kubeconfig}' 2>/dev/null | base64 -d > "${HUB_KUBECONFIG}" 2>/dev/null && [[ -s "${HUB_KUBECONFIG}" ]]; then
            echo "âœ… Kubeconfig extracted (key: kubeconfig)"
          elif kubectl get secret "${HUB_KUBECONFIG_SECRET}" -o jsonpath='{.data.config}' 2>/dev/null | base64 -d > "${HUB_KUBECONFIG}" 2>/dev/null && [[ -s "${HUB_KUBECONFIG}" ]]; then
            echo "âœ… Kubeconfig extracted (key: config)"
          elif kubectl get secret "${HUB_KUBECONFIG_SECRET}" -o jsonpath='{.data.value}' 2>/dev/null | base64 -d > "${HUB_KUBECONFIG}" 2>/dev/null && [[ -s "${HUB_KUBECONFIG}" ]]; then
            echo "âœ… Kubeconfig extracted (key: value)"
          else
            echo "âŒ Failed to extract kubeconfig from secret '${HUB_KUBECONFIG_SECRET}'"
            echo "   Secret should have kubeconfig data under key 'kubeconfig', 'config', or 'value'"
            exit 1
          fi
          chmod 600 "${HUB_KUBECONFIG}"
          export KUBECONFIG="${HUB_KUBECONFIG}"
          echo "âœ… Using hub kubeconfig for cluster operations"
          oc whoami
        else
          echo "â„¹ï¸  No hub kubeconfig secret provided, using in-cluster service account"
        fi

        # Extract kubeconfig for hosted cluster
        echo "ðŸ” Extracting kubeconfig for hosted cluster..."
        KUBECONFIG_SECRET="${HOSTED_CLUSTER_NAME}-admin-kubeconfig"

        if ! oc get secret "${KUBECONFIG_SECRET}" -n "${HOSTED_CLUSTER_NAMESPACE}" > /dev/null 2>&1; then
          echo "âŒ Kubeconfig secret '${KUBECONFIG_SECRET}' not found in namespace '${HOSTED_CLUSTER_NAMESPACE}'"
          exit 1
        fi

        HOSTED_KUBECONFIG="/tmp/hosted-kubeconfig"
        oc get secret "${KUBECONFIG_SECRET}" -n "${HOSTED_CLUSTER_NAMESPACE}" \
          -o jsonpath='{.data.kubeconfig}' | base64 -d > "${HOSTED_KUBECONFIG}"
        chmod 600 "${HOSTED_KUBECONFIG}"

        echo "âœ… Hosted cluster kubeconfig extracted"

        # Set KUBECONFIG to hosted cluster
        export KUBECONFIG="${HOSTED_KUBECONFIG}"

        # Verify access to hosted cluster
        echo "ðŸ” Verifying access to hosted cluster..."
        oc get nodes
        echo "âœ… Successfully connected to hosted cluster"

        # Get cluster info
        echo "ðŸ“‹ Getting hosted cluster information..."
        oc get nodes
        oc get clusterversion || echo "ClusterVersion not available yet"

        # Get ingress controller info
        echo "ðŸ“‹ Getting ingress information..."
        INGRESS_DOMAIN=""
        INGRESS_IP=""

        # Try to get ingress domain from ingress controller
        if oc get ingresscontroller default -n openshift-ingress-operator -o json &>/dev/null; then
          INGRESS_DOMAIN=$(oc get ingresscontroller default -n openshift-ingress-operator \
            -o jsonpath='{.status.domain}' 2>/dev/null || echo "")
          echo "Ingress Domain: ${INGRESS_DOMAIN}"
        fi

        # Fallback: Get from DNS config
        if [[ -z "${INGRESS_DOMAIN}" ]]; then
          INGRESS_DOMAIN=$(oc get dns cluster -o jsonpath='{.spec.baseDomain}' 2>/dev/null || echo "")
          if [[ -n "${INGRESS_DOMAIN}" ]]; then
            INGRESS_DOMAIN="apps.${INGRESS_DOMAIN}"
          fi
          echo "Ingress Domain (from DNS): ${INGRESS_DOMAIN}"
        fi

        # Get ingress service IP (for NodePort/LoadBalancer scenarios)
        if oc get svc -n openshift-ingress router-default &>/dev/null; then
          INGRESS_IP=$(oc get svc -n openshift-ingress router-default \
            -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")

          if [[ -z "${INGRESS_IP}" ]]; then
            # Try hostname instead
            INGRESS_HOSTNAME=$(oc get svc -n openshift-ingress router-default \
              -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
            if [[ -n "${INGRESS_HOSTNAME}" ]]; then
              INGRESS_IP="${INGRESS_HOSTNAME}"
            fi
          fi
        fi

        # For KubeVirt hosted clusters, the ingress may be via NodePort
        if [[ -z "${INGRESS_IP}" ]]; then
          # Get worker node IP as fallback
          WORKER_NODE=$(oc get nodes -l node-role.kubernetes.io/worker -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null || echo "")
          if [[ -n "${WORKER_NODE}" ]]; then
            INGRESS_IP="${WORKER_NODE}"
            echo "Using worker node IP as ingress IP: ${INGRESS_IP}"
          fi
        fi

        echo ""
        echo "ðŸ“Š Ingress Configuration:"
        echo "  Domain: ${INGRESS_DOMAIN:-'Not determined'}"
        echo "  IP: ${INGRESS_IP:-'Not determined'}"

        # Build the EIC host URL
        EIC_HOST=""
        if [[ -n "${INGRESS_DOMAIN}" ]]; then
          # Standard EIC pattern: edge.{ingress-domain}
          EIC_HOST="edge.${INGRESS_DOMAIN}"
        fi

        echo "  EIC Host: ${EIC_HOST:-'Not configured'}"

        # Switch back to hub cluster to create ConfigMap
        if [[ -n "${HUB_KUBECONFIG_SECRET}" ]] && [[ -f "/workspace/hub-kubeconfig/kubeconfig" ]]; then
          export KUBECONFIG="/workspace/hub-kubeconfig/kubeconfig"
        else
          unset KUBECONFIG
        fi

        # Create ConfigMap for endpoint tests
        CONFIGMAP_NAME="cluster-info-hcp-${HOSTED_CLUSTER_NAME}"
        echo ""
        echo "ðŸ“ Creating ConfigMap '${CONFIGMAP_NAME}' for endpoint tests..."

        # Delete existing ConfigMap if present
        oc delete configmap "${CONFIGMAP_NAME}" --ignore-not-found=true

        # Create the ConfigMap
        oc create configmap "${CONFIGMAP_NAME}" \
          --from-literal=host="${EIC_HOST:-edge.apps.${HOSTED_CLUSTER_NAME}.local}" \
          --from-literal=ingressIP="${INGRESS_IP:-127.0.0.1}" \
          --from-literal=clusterName="${HOSTED_CLUSTER_NAME}" \
          --from-literal=clusterNamespace="${HOSTED_CLUSTER_NAMESPACE}" \
          --from-literal=ingressDomain="${INGRESS_DOMAIN:-apps.${HOSTED_CLUSTER_NAME}.local}"

        echo "âœ… ConfigMap created successfully"
        oc get configmap "${CONFIGMAP_NAME}" -o yaml

        # Generate summary
        SUMMARY="HCP Cluster: ${HOSTED_CLUSTER_NAME} | Domain: ${INGRESS_DOMAIN:-N/A} | Ingress: ${INGRESS_IP:-N/A}"
        echo -n "${SUMMARY}" > $(results.cluster-summary.path)

        echo ""
        echo "âœ… HCP validation completed!"
        echo "ðŸ“‹ Summary:"
        echo "  Hosted Cluster: ${HOSTED_CLUSTER_NAME}"
        echo "  Namespace: ${HOSTED_CLUSTER_NAMESPACE}"
        echo "  ConfigMap: ${CONFIGMAP_NAME}"
        echo "  EIC Host: ${EIC_HOST:-Not configured}"
        echo "  Ingress IP: ${INGRESS_IP:-Not determined}"
