#!/bin/bash

# SPDX-FileCopyrightText: 2025 SAP edge team
# SPDX-FileContributor: Manjun Jiao (@mjiao)
#
# SPDX-License-Identifier: Apache-2.0

# troubleshoot-terraform.sh
# Comprehensive troubleshooting script for Terraform lifecycle issues

set -e

CLUSTER_NAME=${1:-"sap-eic-rosa"}
AWS_REGION=${2:-"eu-north-1"}
ACTION=${3:-"diagnose"}

echo "ğŸ”§ Terraform Troubleshooting Tool"
echo "Cluster: $CLUSTER_NAME | Region: $AWS_REGION | Action: $ACTION"
echo "=========================================="

# Function to show terraform state vs AWS reality
show_state_drift() {
    echo ""
    echo "ğŸ“Š TERRAFORM STATE vs AWS REALITY:"
    echo "-----------------------------------"

    echo "ğŸ” Terraform State Resources:"
    if terraform state list 2>/dev/null | grep -q .; then
        terraform state list
    else
        echo "   (No resources in Terraform state)"
    fi

    echo ""
    echo "ğŸ” AWS Resources That Actually Exist:"

    # Check each resource type
    local aws_resources_found=0

    # ElastiCache
    if aws elasticache describe-cache-subnet-groups --cache-subnet-group-name "$CLUSTER_NAME-redis-subnet-group" --region "$AWS_REGION" &>/dev/null; then
        echo "   âœ“ ElastiCache Subnet Group: $CLUSTER_NAME-redis-subnet-group"
        aws_resources_found=1
    fi

    if aws elasticache describe-replication-groups --replication-group-id "$CLUSTER_NAME-redis" --region "$AWS_REGION" &>/dev/null; then
        echo "   âœ“ ElastiCache Replication Group: $CLUSTER_NAME-redis"
        aws_resources_found=1
    fi

    # S3
    if aws s3api head-bucket --bucket "$CLUSTER_NAME-quay-registry" --region "$AWS_REGION" &>/dev/null; then
        echo "   âœ“ S3 Bucket: $CLUSTER_NAME-quay-registry"
        aws_resources_found=1
    fi

    # RDS
    if aws rds describe-db-instances --db-instance-identifier "$CLUSTER_NAME-postgres" --region "$AWS_REGION" &>/dev/null; then
        echo "   âœ“ RDS Instance: $CLUSTER_NAME-postgres"
        aws_resources_found=1
    fi

    if aws rds describe-db-subnet-groups --db-subnet-group-name "$CLUSTER_NAME-postgres-subnet-group" --region "$AWS_REGION" &>/dev/null; then
        echo "   âœ“ RDS Subnet Group: $CLUSTER_NAME-postgres-subnet-group"
        aws_resources_found=1
    fi

    # Security Groups
    if aws ec2 describe-security-groups --filters Name=group-name,Values="$CLUSTER_NAME-postgres-sg" --region "$AWS_REGION" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null | grep -v "None" &>/dev/null; then
        echo "   âœ“ Security Group (PostgreSQL): $CLUSTER_NAME-postgres-sg"
        aws_resources_found=1
    fi

    if aws ec2 describe-security-groups --filters Name=group-name,Values="$CLUSTER_NAME-redis-sg" --region "$AWS_REGION" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null | grep -v "None" &>/dev/null; then
        echo "   âœ“ Security Group (Redis): $CLUSTER_NAME-redis-sg"
        aws_resources_found=1
    fi

    # IAM
    if aws iam get-user --user-name "$CLUSTER_NAME-quay-s3-user" &>/dev/null; then
        echo "   âœ“ IAM User: $CLUSTER_NAME-quay-s3-user"
        aws_resources_found=1
    fi

    if [[ $aws_resources_found -eq 0 ]]; then
        echo "   (No AWS resources found)"
    fi
}

# Function to show detailed resource status
show_detailed_status() {
    echo ""
    echo "ğŸ” DETAILED RESOURCE STATUS:"
    echo "----------------------------"

    # Check RDS status
    if aws rds describe-db-instances --db-instance-identifier "$CLUSTER_NAME-postgres" --region "$AWS_REGION" &>/dev/null; then
        local rds_status
        rds_status=$(aws rds describe-db-instances --db-instance-identifier "$CLUSTER_NAME-postgres" --region "$AWS_REGION" --query 'DBInstances[0].DBInstanceStatus' --output text)
        echo "   RDS PostgreSQL Status: $rds_status"
    fi

    # Check ElastiCache status
    if aws elasticache describe-replication-groups --replication-group-id "$CLUSTER_NAME-redis" --region "$AWS_REGION" &>/dev/null; then
        local redis_status
        redis_status=$(aws elasticache describe-replication-groups --replication-group-id "$CLUSTER_NAME-redis" --region "$AWS_REGION" --query 'ReplicationGroups[0].Status' --output text 2>/dev/null)
        echo "   ElastiCache Redis Status: $redis_status"
    fi

    # Check if ROSA cluster exists
    echo ""
    echo "ğŸ” ROSA CLUSTER STATUS:"
    if rosa list clusters 2>/dev/null | grep -q "$CLUSTER_NAME"; then
        local rosa_status
        rosa_status=$(rosa describe cluster "$CLUSTER_NAME" --output json 2>/dev/null | jq -r '.status.state // "unknown"' 2>/dev/null || echo "unknown")
        echo "   ROSA Cluster Status: $rosa_status"
    else
        echo "   ROSA Cluster: Not found"
    fi
}

# Function to provide specific recovery steps
suggest_recovery() {
    echo ""
    echo "ğŸ›   RECOVERY SUGGESTIONS:"
    echo "------------------------"

    local has_state
    has_state=$(terraform state list 2>/dev/null | wc -l)
    local has_aws_resources=0

    # Quick check for AWS resources
    if aws s3api head-bucket --bucket "$CLUSTER_NAME-quay-registry" &>/dev/null ||
       aws rds describe-db-instances --db-instance-identifier "$CLUSTER_NAME-postgres" &>/dev/null ||
       aws elasticache describe-replication-groups --replication-group-id "$CLUSTER_NAME-redis" &>/dev/null; then
        has_aws_resources=1
    fi

    if [[ $has_state -gt 0 && $has_aws_resources -eq 1 ]]; then
        echo "   âœ… SCENARIO: Normal state - resources exist in both Terraform and AWS"
        echo "   ğŸ’¡ Try: terraform plan (should show no changes)"
        echo "   ğŸ’¡ If destroy needed: terraform destroy"

    elif [[ $has_state -eq 0 && $has_aws_resources -eq 1 ]]; then
        echo "   âš ï¸  SCENARIO: STATE DRIFT - AWS resources exist but not in Terraform state"
        echo "   ğŸ’¡ Option A: Clean up manually: ./cleanup-orphaned-resources.sh $CLUSTER_NAME $AWS_REGION false"
        echo "   ğŸ’¡ Option B: Import resources: terraform import [resource] [id]"
        echo "   ğŸ’¡ Option C: Use different cluster name"

    elif [[ $has_state -gt 0 && $has_aws_resources -eq 0 ]]; then
        echo "   ğŸ”„ SCENARIO: Terraform thinks resources exist but they're gone from AWS"
        echo "   ğŸ’¡ Refresh state: terraform refresh"
        echo "   ğŸ’¡ Then plan: terraform plan"

    elif [[ $has_state -eq 0 && $has_aws_resources -eq 0 ]]; then
        echo "   âœ… SCENARIO: Clean slate - ready for fresh deployment"
        echo "   ğŸ’¡ Proceed with: terraform plan && terraform apply"

    else
        echo "   â“ SCENARIO: Mixed state - manual investigation needed"
        echo "   ğŸ’¡ Check: terraform plan"
        echo "   ğŸ’¡ Check: ./preflight-check.sh $CLUSTER_NAME $AWS_REGION"
    fi
}

# Main logic
case $ACTION in
    "diagnose"|"check")
        show_state_drift
        show_detailed_status
        suggest_recovery
        ;;
    "clean")
        echo "ğŸ§¹ Running cleanup sequence..."
        ./cleanup-orphaned-resources.sh "$CLUSTER_NAME" "$AWS_REGION" false
        echo "âœ… Cleanup completed"
        ;;
    "fix-state")
        echo "ğŸ”§ Fixing Terraform state (removing stale ROSA resources)..."
        ./fix-state-before-next-run.sh "$CLUSTER_NAME" "$AWS_REGION" false
        ;;
    "reset")
        echo "ğŸ”„ Performing complete reset..."
        echo "1. Refreshing Terraform state..."
        terraform refresh || echo "   (Refresh failed - continuing)"
        echo "2. Running cleanup..."
        ./cleanup-orphaned-resources.sh "$CLUSTER_NAME" "$AWS_REGION" false
        echo "3. Final state check..."
        show_state_drift
        echo "âœ… Reset completed"
        ;;
    *)
        echo "Usage: $0 [cluster_name] [region] [action]"
        echo ""
        echo "Actions:"
        echo "  diagnose  - Show state drift and recovery suggestions (default)"
        echo "  clean     - Clean up orphaned AWS resources (in AWS, not state)"
        echo "  fix-state - Remove stale ROSA cluster from Terraform state"
        echo "  reset     - Full reset (refresh + clean)"
        echo ""
        echo "Examples:"
        echo "  $0 sap-eic-rosa eu-north-1 diagnose"
        echo "  $0 sap-eic-rosa eu-north-1 fix-state"
        echo "  $0 sap-eic-rosa eu-north-1 clean"
        echo "  $0 sap-eic-rosa eu-north-1 reset"
        ;;
esac